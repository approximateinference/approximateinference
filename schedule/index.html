<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="author" content="Dustin Tran">
  <link rel="shortcut icon" href="/img/favicon.ico" type="image/x-icon">
  <title>Approximate Inference - Schedule</title>

  <!-- CSS -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.1/css/bootstrap.min.css">
  <link href="http://maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet">
  <link rel="stylesheet" href="/css/main.css">

  <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
  <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
  <![endif]-->
</head>
<body>
  <div class="container">

    <div class="row" style="padding:20px">

      <div class="hidden-xs col-sm-3 col-md-2">
      </div>

      <div class="col-xs-12 col-sm-12 col-md-9">
        <div class="row" style="margin-bottom:-10px;">
          <div class="col-xs-12 hidden-sm hidden-md hidden-lg">
            <!--
            <a href="http://nips.cc">
              <img src="/img/nips.svg" style="margin:0px -90px
              0 0; height:140px; width:250px;">
            </a>
            -->
          </div>
          <div class="hidden-xs">
            <!--
            <a href="http://nips.cc">
              <img src="/img/nips.svg" class="pull-right" style="margin:0px -90px
              0 0; height:140px; width:250px;">
            </a>
            -->
          </div>
          <h2>Symposium on Advances in Approximate Bayesian Inference</h2>
          <p class="lead">
            December 2, 2018<br>
            <a href="https://goo.gl/maps/GZ2CkVfpFhL2">Le 1000 Conference Center</a><br>
            <a href="https://goo.gl/maps/GZ2CkVfpFhL2">1000 Rue de la Gauchetière Ouest</a><br> 
            <a href="https://goo.gl/maps/GZ2CkVfpFhL2">Montréal, QC H3B 0A2, Canada</a><br>
          </p>
        </div>
      </div>

       <div class="col-xs-12 col-sm-3 col-md-2" id="sidebar" role="navigation">
        <hr>
        <ul class="nav nav-pills nav-stacked">
          <li><a href="../">Home</a></li>
          <li><a href=".">Schedule</a></li>
          <li><a href="../call">Call for Papers</a></li>
          <li><a href="../accepted">Accepted Papers</a></li>
          <li><a href="../program">Program Committee</a></li>
        </ul>
        <hr>
        <ul class="nav temp">
          <li style="padding:0px 15px 5px;">Organizers</li>
            <li><a href="https://cheng-zhang.org/">Cheng Zhang</a></li>
            <li><a href="http://dawenl.github.io/">Dawen Liang</a></li>
            <li><a href="http://franrruiz.github.io">Francisco Ruiz</a></li>
            <li><a href="http://mlg.eng.cam.ac.uk/thang/">Thang Bui</a></li>
        </ul>
        <hr>
        <ul class="nav temp">
          <li style="padding:0px 15px 5px;">Advisory Committee</li>
            <li><a href="https://www.ceremade.dauphine.fr/~xian/">Christian Robert</a></li>
            <li><a href="http://www.cs.columbia.edu/~blei">David Blei</a></li>
            <li><a href="http://dustintran.com/">Dustin Tran</a></li>
            <li><a href="http://jamesmc.com">James McInerney</a></li>
            <li><a href="http://www.stephanmandt.com">Stephan Mandt</a></li>
        </ul>
      </div>

      <div class="col-xs-12 col-sm-9 col-md-9">
        <div class="row">
          <hr>
          <!--
          <p><strong>
          The workshop's recording is available on
          <a href="https://www.youtube.com/playlist?list=PLsatQfvo0v3sUhi3ijRme9MyqwLL5EOiG">
          Youtube</a>.
          </strong></p>
          -->
          <h3>Registration</h3>
          <!-- <h4>Chair: Francisco Ruiz</h4> -->
          <table class="table" style="margin-bottom:0px;">
            <tbody>
              <tr>
                <td width="12%">7:30 - 8:30</td>
                <td><strong>Registration (Coffee will be served)</strong></td>
              </tr>
            </tbody>
          </table>
          <h3>Session 1</h3>
          <!-- <h4>Chair: Francisco Ruiz</h4> -->
          <table class="table" style="margin-bottom:0px;">
            <tbody>
              <tr>
                <td width="12%">8:30 - 8:40</td>
                <td><strong>Introduction</strong></td>
              </tr>
            </tbody>
          </table>
          <table class="table" style="margin-bottom:0px;">
            <tbody>
              <tr>
                <td width="12%">8:40 - 9:10</td>
                <td width="8%">Invited</td>
                <td>
                TBD<!-- Jean-Michel Marin -->
                <!--: <em></em> -->
                <!-- <a href="/2018/schedule/Marin2018.pdf"
                class="btn btn-default btn-xs">Slides</a> -->
                </td>
              </tr>
              <tr>
                <td>9:10 - 9:30</td>
                <td>Contributed</td>
                <td>
                Maria I. Gorinova: <em>Automatic Reparameterisation in Probabilistic Programming</em>
                <!-- <a href="/2018/schedule/Gorinova2018.pdf" -->
                <!-- class="btn btn-default btn-xs">Slides</a> -->
                </td>
              </tr>
              <tr>
                <td>9:30 - 10:00</td>
                <td>Invited</td>
                <td>
                Tamara Broderick
                <!-- : <em></em> -->
                <!-- <a href="/2018/schedule/Broderick2018.pdf"
                class="btn btn-default btn-xs">Slides</a> -->
                </td>
              </tr>
            </tbody>
          </table>
          <table class="table">
            <tbody>
              <tr>
                <td width="12%">10:00 - 11:00</td>
                <td><strong>Coffee Break and Poster Session (Paper IDs 1-24)</strong></td>
              </tr>
            </tbody>
          </table>
        </div>

        <div class="row">
          <h3>Session 2</h3>
          <!-- <h4>Chair: James McInerney</h4> -->
          <table class="table" style="margin-bottom:0px;">
            <tbody>
              <tr>
                <td width="12%">11:00 - 11:20</td>
                <td width="8%">Contributed</td>
                <td>
                George Tucker: <em>Doubly Reparameterized Gradient Estimators for Monte Carlo Objectives</em>
                <!-- <a href="/2018/schedule/Tucker2018.pdf"
                class="btn btn-default btn-xs">Slides</a> -->
                </td>
              </tr>
              <tr>
                <td>11:20 - 11:50</td>
                <td>Invited</td>
                <td>
                Tom Rainforth
                <!-- : <em></em> -->
                <!-- <a href="/2018/schedule/Rainforth2018.pdf"
                class="btn btn-default btn-xs">Slides</a> -->
                </td>
              </tr>
              <tr>
                <td>11:50 - 12:10</td>
                <td>Contributed</td>
                <td>
                David Burt: <em>Explicit Rates of Convergence for Sparse Variational Inference in Gaussian Process Regression</em>
                <!-- <a href="/2018/schedule/Burt2018.pdf"
                class="btn btn-default btn-xs">Slides</a> -->
                </td>
              </tr>
            </tbody>
          </table>
        </div>

        <div class="row">
          <table class="table">
            <tbody>
              <tr>
                <td width="12%">12:10 - 13:40</td>
                <td><strong>Lunch Break (on your own)</strong></td>
              </tr>
            </tbody>
          </table>
        </div>

        <div class="row">
          <h3>Session 3</h3>
          <!-- <h4>Chair: Cheng Zhang</h4> -->
          <table class="table" style="margin-bottom:0px;">
            <tbody>
              <tr>
                <td width="12%">13:40 - 14:10</td>
                <td width="8%">Invited</td>
                <td>
                Thomas Schon
                <!-- : <em></em> -->
                <!-- <a href="/2018/schedule/Schon2018.pdf"
                class="btn btn-default btn-xs">Slides</a> -->
                </td>
              </tr>
              <tr>
                <td>14:10 - 14:30</td>
                <td>Contributed</td>
                <td>
                Badr-Eddine Chérief-Abdellatif: <em>Consistency of ELBO maximization for model selection</em>
                <!-- <a href="/2018/schedule/CheriefAbdellatif2018.pdf"
                class="btn btn-default btn-xs">Slides</a> -->
                </td>
              </tr>
              <tr>
                <td>14:30 - 15:00</td>
                <td>Invited</td>
                <td>
                Sebastian Nowozin: <em>Debiasing Approximate Inference</em>
                <!-- <a href="/2018/schedule/Nowozin2018.pdf"
                class="btn btn-default btn-xs">Slides</a> -->
                </td>
              </tr>
            </tbody>
          </table>
        </div>

        <div class="row">
          <table class="table">
            <tbody>
              <tr>
                <td width="12%">15:00 - 16:00</td>
                <td><strong>Coffee Break and Poster Session (Paper IDs 25-45)</strong></td>
              </tr>
            </tbody>
          </table>
        </div>

        <div class="row">
          <h3>Session 4</h3>
          <!-- <h4>Chair: Stephan Mandt</h4> -->
          <table class="table" style="margin-bottom:0px;">
            <tbody>
              <tr>
                <td width="12%">16:00 - 16:20</td>
                <td width="8%">Contributed</td>
                <td>
                Will Grathwohl: <em>Scalable Reversible Generative Models with Free-form Continuous Dynamics</em>
                <!-- <a href="/2018/schedule/Grathwohl2018.pdf"
                class="btn btn-default btn-xs">Slides</a> -->
                </td>
              </tr>
              <tr>
                <td>16:20 - 16:50</td>
                <td>Invited</td>
                <td>
                Emityaz Khan
                <!-- : <em></em> -->
                <!-- <a href="/2018/schedule/Khan2018.pdf"
                class="btn btn-default btn-xs">Slides</a> -->
                </td>
              </tr>
              <tr>
                <td>16:50 - 17:10</td>
                <td>Contributed</td>
                <td>
                Matthew Hoffman: <em>NeuTra-lizing Bad Geometry in Hamiltonian Monte
                Carlo Using Neural Transport</em>
                <!-- <a href="/2018/schedule/Hoffman2018.pdf"     -->
                <!-- class="btn btn-default btn-xs">Slides</a> -->
                </td>
              </tr>
            </tbody>
          </table>
        </div>

        <div class="row">
          <table class="table">
            <tbody>
              <tr>
                <td width="12%">17:10 - 18:00 </td>
                <td><strong>Panel</strong>
                <br>
                Alexander Alemi, David Duvenaud, Kevin Murphy, Ole Winther, Tamara Broderick
                <br>
                Moderator: Yingzhen Li
                </td>
              </tr>
            </tbody>
          </table>
        </div>

        <!-- 
        <div class="row">
          <h3>Abstracts</h3>
          <hr>
          <h4><a href="http://homepages.inf.ed.ac.uk/imurray2">Iain Murray</a>
          (University of Edinburgh)</h4>
          <h4>Learning priors, likelihoods, or posteriors</h4>
          <p>
          <strong>Abstract</strong>.
          As the description of the workshop states: variational and
          Monte Carlo methods are currently the mainstream techniques
          for approximate Bayesian inference. However, we can also
          apply machine learning models to solve inference problems in
          several ways. Firstly, there's no point doing careful
          Bayesian inference if the model is silly. We can represent
          good models, often with hard-to-specify priors or expensive
          likelihoods, with surrogates learned from data. Secondly, we
          can learn how to do inference from experience or simulated
          data. However, this is a workshop, so we can have a friendly
          conversation... There's a huge choice of what to do here,
          and frankly it's often not clear what the best approach is,
          and there are a lot of open theoretical questions. I'll give
          some thoughts, but may raise more questions than answers.
          </p>
          <h4><a href="http://yingzhenh4.net/">Yingzhen Li</a>
          (University of Cambridge)</h4>
          <h4>Gradient Estimators for Implicit Models</h4>
          <p>
          <strong>Abstract</strong>.
          This talk is organised in two parts. First I will start by
          revisiting fundamental tractability issues of Bayesian
          computation and argue that density evaluation of the
          approximate posterior is mostly unnecessary. Then I will
          present one of our recent work on an algorithm for fitting
          implicit posterior distributions. In a nutshell, we proposed
          a gradient estimation method that allow variational
          inference to be applied to those approximate distributions
          without a tractable density.
          </p>
          <h4><a href="http://dawenl.github.io">Dawen Liang</a>
          (Netflix)</h4>
          <h4>Variational Autoencoders for Recommendation</h4>
          <p>
          <strong>Abstract</strong>.
          In this talk, I will present how we extend variational
          autoencoders (VAEs) to collaborative filtering for implicit
          feedback. We introduce a different regularization parameter
          for the learning objective, which proves to be crucial for
          achieving competitive performance. The resulting model and
          learning algorithm has information-theoretic connections to
          maximum entropy discrimination and the information
          bottleneck principle, as well as many recent work on
          understanding the trade-offs in learning latent variable
          models with VAEs. Empirically, we show that the proposed
          approach significantly outperforms state-of-the-art
          baselines on several real-world datasets. Finally, we
          identify the pros and cons of employing a principled
          Bayesian inference approach and characterize settings where
          it provides the most significant improvements.
          </p>
          <h4><a href="http://adamian.github.io">Andreas
          Damianou</a> (Amazon)</h4>
          <h4>Variational inference in deep Gaussian processes</h4>
          <p>
          <strong>Abstract</strong>.
          Combining deep nets with probabilistic reasoning is
          challenging, because uncertainty needs to be propagated
          across the neural network during inference. This comes in
          addition to the (easier) propagation of gradients. In this
          talk I will talk about a family of variational approximation
          methods developed to tackle the aforementioned computational
          issue in Deep Gaussian processes, which can be seen as
          non-parametric Bayesian neural networks.
          </p>
          <h4><a href="https://www.hiit.fi/u/ahonkela/">Antti
          Honkela</a> (University of Helsinki)</h4>
          <h4>Differential privacy and Bayesian learning</h4>
          <p>
          <strong>Abstract</strong>.
          Differential privacy allows deriving strong privacy
          guarantees for algorithms using private data. In my talk I
          will introduce and review different approaches for
          differentially private Bayesian learning building upon
          different forms of exact and approximate inference.
          </p>
        -->

      </div>

    </div>

    <hr>

    <footer>
    &nbsp;
    </footer>

  </div>

  <!-- JavaScript -->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.1/js/bootstrap.min.js"></script>
  <script type="text/javascript"
     src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>
  <script type="text/javascript" src="/js/main.js"></script>
</body>
</html>
